{
  "level": 5,
  "title": "Data Collection, Privacy & Civil Liberties",
  "scenarios": [
    {
      "scenario_id": "L5-S1",
      "title": "The Platform That Remembers",
      "prompt": "A city plans to boost resident engagement by launching a Civic AI advisor, an AI platform for real-time conversations that collects and stores feedback and suggestions on community services.",
      "choices": {
        "A": "By default, store conversations and allow users to delete them.",
        "B": "Offer an opt-in for participation and protect privacy with fake data and secure learning methods.",
        "C": "Choose to have no data retained and allow all personalization to occur solely on the device, enhancing user privacy and security."
      },
      "toolkit_cues": "What benefits come from memory vs. chilling effects? What privacy-preserving defaults fit?",
      "p3_cues": "People (speech/privacy), Planet (local vs. cloud energy), Parity (opt-in exclusion).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Provide deletion tools + reminders",
            "Limit internal access + logging",
            "Run red-team privacy tests"
          ],
          "B": [
            "Require explicit opt-in choices",
            "Apply DP/synthetic safeguards",
            "Publish participation + impact stats"
          ],
          "C": [
            "Enable local profiles + backups",
            "Offer device performance guidance",
            "Document feature tradeoffs clearly"
          ]
        },
        "metrics": [
          "Consent rate %",
          "Data deletion requests",
          "Privacy compliance %"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Impact Explorer, Weighing Options"
    },
    {
      "scenario_id": "L5-S2",
      "title": "Discount for Location",
      "prompt": "A rideshare service offers lower fares to users who share their location history, raising privacy concerns. While it sounds like a deal too good to pass up, it raises serious privacy concerns. What would you recommend?",
      "choices": {
        "A": "Implement an opt-in model with transparent data usage policies.",
        "B": "Provide users with complete control over their data sharing preferences.",
        "C": "Offer tiered discounts based on the depth of data shared while ensuring robust data protection measures."
      },
      "toolkit_cues": "Is price-for-privacy coercive here? What re-identification risks follow?",
      "p3_cues": "People (movement privacy), Planet (edge compute), Parity (regressive tradeoffs).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Explain pricing-for-data tradeoffs",
            "Add easy revoke + delete options",
            "Ban downstream resale in contracts"
          ],
          "B": [
            "Provide per-signal toggles",
            "Default to minimum sharing",
            "Audit default effects quarterly"
          ],
          "C": [
            "Publish clear tier matrix",
            "Cap data scope per tier",
            "Review equity impacts regularly"
          ]
        },
        "metrics": [
          "Opt-in rate %",
          "User control usage",
          "Privacy compliance %"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Values Explainer Cards, Future Story"
    },
    {
      "scenario_id": "L5-S3",
      "title": "Buying Brokered Data",
      "prompt": "A state is exploring collaboration with a data broker to improve strategic planning, identify growth opportunities, and assess program effectiveness. What is your advice?",
      "choices": {
        "A": "Engage stakeholders to ensure that data usage aligns with community needs and preferences.",
        "B": "Establish clear objectives for how the data will be used to measure program success and impact.",
        "C": "Avoid using brokered data if it does not prioritize transparency and accountability in data collection and usage."
      },
      "toolkit_cues": "Who becomes newly visible or targeted? What legitimacy and usage limits are required?",
      "p3_cues": "People (expectations), Planet (storage load), Parity (visibility of vulnerable groups).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Hold community listening sessions",
            "Co-design acceptable-use rules",
            "Publish engagement summary + changes"
          ],
          "B": [
            "Define narrow use cases",
            "Set success/exit criteria",
            "Report outcomes vs. harms"
          ],
          "C": [
            "Document rationale + alternatives",
            "Invest in ethical first-party data",
            "Revisit decision annually"
          ]
        },
        "metrics": [
          "Stakeholder engagement rate",
          "Transparency score",
          "Accountability compliance %"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Impact Explorer, Ethics Frame"
    },
    {
      "scenario_id": "L5-S4",
      "title": "Health Chat Sharing",
      "prompt": "A wellness chatbot shares information that doesn't include any personal details with researchers. However, there is still a chance that someone could figure out who you are from the information shared.",
      "choices": {
        "A": "Collaborate with privacy experts to assess potential risks; develop innovative privacy-preserving technologies.",
        "B": "Continue implementing the chatbot, conduct regular audits of data-sharing practices, and enhance transparency for users.",
        "C": "Develop an educational campaign to inform users about data privacy and encourage community feedback on policies."
      },
      "toolkit_cues": "What residual re-ID risks remain? What safer sharing options exist for research?",
      "p3_cues": "People (stigma), Planet (DP/synthetic compute), Parity (who benefits).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Commission re-ID risk assessment",
            "Implement mitigations (k-anon/DP)",
            "Update user notices + choices"
          ],
          "B": [
            "Publish sharing partners + purposes",
            "Post audit summaries + fixes",
            "Track opt-outs + complaints"
          ],
          "C": [
            "Provide in-product privacy tips",
            "Host user feedback channels",
            "Iterate policies on published input"
          ]
        },
        "metrics": [
          "Re-identification risk score",
          "Privacy-preserving tech usage %",
          "Transparency score"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Future Story, Weighing Options"
    },
    {
      "scenario_id": "L5-S5",
      "title": "Face Entry Pilot",
      "prompt": "A corporate office is testing a facial recognition system for employee entry to enhance security and reduce wait times, raising ethical and societal questions about privacy and surveillance. How would you handle this?",
      "choices": {
        "A": "Offer employees the option to opt-out and utilize other forms of entry, such as key cards or PINs.",
        "B": "Establish an independent oversight committee to monitor the implementation and address any ethical concerns that arise.",
        "C": "Involve employees in the decision-making process through surveys or focus groups to gauge their feelings about the system."
      },
      "toolkit_cues": "Is biometric entry necessary and proportional? What oversight and opt-outs enforce trust?",
      "p3_cues": "People (biometric risk), Planet (cameras), Parity (accuracy gaps).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Maintain card/PIN lanes",
            "Monitor opt-out friction",
            "Ban retaliation for opting out"
          ],
          "B": [
            "Charter a cross-functional board",
            "Set bias/accuracy test schedule",
            "Publish incident + drift reports"
          ],
          "C": [
            "Run anonymized sentiment surveys",
            "Include diverse shift/role reps",
            "Share findings + action items"
          ]
        },
        "metrics": [
          "Opt-out rate %",
          "Accuracy by demographic",
          "Employee satisfaction"
        ],
        "owner_required": true,
        "review_default_days": 60
      },
      "toolkit_references": "Values Explainer Cards, Ethics Frame"
    }
  ]
}
