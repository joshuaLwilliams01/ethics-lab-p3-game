{
  "level": 2,
  "title": "Algorithmic Decision-Making & Fairness",
  "scenarios": [
    {
      "scenario_id": "L2-S1",
      "title": "The Screening Model",
      "prompt": "A corporation has implemented an automated hiring tool with high precision, but it still sees a 10â€“15% disparity in outcomes among different demographic groups. Balancing fairness with efficiency is challenging, as retraining the algorithm may delay hiring processes. What would you do?",
      "choices": {
        "A": "Continue to implement and include human-in-the-loop appeals.",
        "B": "Stop implementation for 6 weeks to optimize equalized odds, accepting lower throughput.",
        "C": "Hybrid approach: restrict use for roles with minimal disparity; use manual processes for others."
      },
      "toolkit_cues": "Which fairness goal are we optimizing? Who absorbs false negatives?",
      "p3_cues": "People (rejected applicants), Planet (retraining compute), Parity (opportunity gaps).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Publish appeal flow + deadlines",
            "Monitor adverse impact by role",
            "Blind sensitive attributes where feasible"
          ],
          "B": [
            "Freeze automated screening in flagged roles",
            "Retrain w/ fairness constraints + evals",
            "Publish tradeoff memo (precision/recall)"
          ],
          "C": [
            "Post role matrix (auto vs. manual)",
            "Train standardized manual rubrics",
            "Review matrix every 60 days"
          ]
        },
        "metrics": [
          "Demographic parity %",
          "Appeal success rate"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Values Explainer Cards, Impact Explorer"
    },
    {
      "scenario_id": "L2-S2",
      "title": "Credit by Phone",
      "prompt": "A lender is using phone bills and location data to evaluate loan eligibility. As this practice becomes more widespread, the convenience of quick approvals comes with growing concerns about your privacy. What is your decision on this?",
      "choices": {
        "A": "Implement the system, but provide clear options for users to opt out and offer thorough explanations.",
        "B": "Encourage participation only through an opt-in model that includes independent bias audits.",
        "C": "Test the system on small loans initially and analyze the outcomes."
      },
      "toolkit_cues": "What privacy harms could arise from location scoring? What safer pilots exist?",
      "p3_cues": "People (over-indebted), Planet (always-on scoring), Parity (data-poor applicants).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Provide notices + scoring factors",
            "Offer non-location path for thin-file",
            "Add independent dispute hotline"
          ],
          "B": [
            "Require explicit consent summaries",
            "Commission + publish bias audit",
            "Set retention + re-use limits"
          ],
          "C": [
            "Define pilot size + success thresholds",
            "Cap APR/fees to prevent harm",
            "Publish pilot results + decision"
          ]
        },
        "metrics": [
          "Opt-in rate %",
          "Bias audit results",
          "Appeal success rate"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Future Story, Weighing Options"
    },
    {
      "scenario_id": "L2-S3",
      "title": "Webcam Exams",
      "prompt": "A recent study shows that online proctoring systems are incorrectly flagging 'suspicious gaze' more often for dark-skinned students, raising serious concerns about fairness and accuracy in digital testing. What would you do if you needed to solve this problem?",
      "choices": {
        "A": "Continue using the system, but ensure to incorporate human checks and perform additional calibration.",
        "B": "Provide alternatives to webcams, such as oral presentations or portfolios.",
        "C": "Pause the system until the error gaps have been resolved."
      },
      "toolkit_cues": "Who is mis-flagged and with what consequences? What low-intrusion options exist?",
      "p3_cues": "People (stress/dignity), Planet (video monitoring), Parity (false positives by skin tone).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Calibrate for tone/lighting/access",
            "Human review before penalties",
            "Rapid appeal channel for students"
          ],
          "B": [
            "Stand up oral/portfolio options",
            "Train graders for consistency",
            "Disclose equivalency to students"
          ],
          "C": [
            "Suspend tool; use interim methods",
            "Contract vendor for targeted fixes",
            "Pilot w/ diverse cohorts + publish results"
          ]
        },
        "metrics": [
          "False positive rate by demographic",
          "Alternative assessment usage %"
        ],
        "owner_required": true,
        "review_default_days": 60
      },
      "toolkit_references": "Impact Explorer, Weighing Options"
    },
    {
      "scenario_id": "L2-S4",
      "title": "ER Triage Model",
      "prompt": "A new predictive analytics model for emergency department (ED) triage is revolutionizing how hospitals handle wait times, significantly reducing them. However, it seems that patients with less extensive medical histories aren't ranking as high in this system. How would you handle this?",
      "choices": {
        "A": "Continue implementing the model, but include a doctor override functionality.",
        "B": "Impose penalties for model uncertainty to enhance decision-making safety by promoting caution with limited historical data.",
        "C": "Set aside 'equity slots' in the queue to make sure that underrepresented individuals or groups have fair access."
      },
      "toolkit_cues": "Where is data missing and how does it bias priority? Who can override and how?",
      "p3_cues": "People (care outcomes), Planet (compute), Parity (patients with thin histories).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Log override reasons/outcomes",
            "Flag uncertainty for thin histories",
            "Weekly case review of overrides"
          ],
          "B": [
            "Boost risk for sparse histories",
            "Validate effect on waits/outcomes",
            "Tune thresholds weekly"
          ],
          "C": [
            "Define eligibility + verification",
            "Reserve fixed capacity per shift",
            "Publish equity access metrics"
          ]
        },
        "metrics": [
          "Triage accuracy by patient history",
          "Override usage rate",
          "Equity slot utilization"
        ],
        "owner_required": true,
        "review_default_days": 30
      },
      "toolkit_references": "Future Story, Ethics Frame"
    },
    {
      "scenario_id": "L2-S5",
      "title": "Patrol Maps",
      "prompt": "A police resource tool directs additional patrols to crime 'hot spots,' creating a potential cycle of escalating tensions and safety concerns. How would you address this?",
      "choices": {
        "A": "Allocate funding for community initiatives and enforce transparent public audits.",
        "B": "Implement randomized block trials to assess effectiveness and gather data.",
        "C": "Prioritize investment in community safety programs as alternatives to traditional policing."
      },
      "toolkit_cues": "Is our process fair even if outcomes improve? What alternatives reduce surveillance load?",
      "p3_cues": "People (chilling effects), Planet (patrol miles), Parity (over-policing hot spots).",
      "toolkit_flow": {
        "order": [],
        "prompts": [],
        "quick_actions": {
          "A": [
            "Reallocate budget to prevention",
            "Publish deployment/stops data",
            "Hold monthly community oversight"
          ],
          "B": [
            "Pre-register design + outcomes",
            "Brief communities pre/post trial",
            "Publish full results + data"
          ],
          "C": [
            "Fund crisis/mediation/Env. design",
            "Coordinate 911/311 triage routes",
            "Track response + resolution times"
          ]
        },
        "metrics": [
          "Crime reduction in hot spots",
          "Community trust score",
          "Surveillance distribution"
        ],
        "owner_required": true,
        "review_default_days": 90
      },
      "toolkit_references": "Values Explainer Cards, Weighing Options"
    }
  ]
}
